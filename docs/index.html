<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>HDRFlow++: Benchmarking Real-Time HDR Video Reconstruction under Global Motions</title>
  <link rel="stylesheet" href="css/style.css" />
</head>
<body>
  <!-- Hero Section -->
  <header id="hero">
    <video src="assets/teaser_hdrflow.mp4" autoplay loop muted playsinline></video>
    <h1>HDRFlow++: Benchmarking Real-Time  HDR Video Reconstruction under Global Motions</h1>
    <p class="subtitle">SIGGRAPH Asia 2021 · Park et al.</p>
  </header>

  <!-- Abstract Section -->
<!-- Abstract Section -->
  <section id="abstract">
    <h2>Abstract</h2>
    <p>
      Real-time HDR video reconstruction remains challenging under large-scale camera and object motion,
      primarily due to misalignment across multi-exposure frames and the lack of motion-aware fusion strategies.
      Existing methods suffer from degraded reconstruction quality in dynamic environments
      and are often trained on limited datasets with minimal motion diversity.
    </p>
    <p>
      We propose <strong>HDRFlow++</strong>, a motion-robust HDR reconstruction framework that integrates a pretrained RAFT-based feature extractor 
      as a structural prior to guide feature-level alignment and fusion. By leveraging high-quality optical flow in the feature space, 
      our model enhances spatial consistency under severe global motion while maintaining real-time performance.
    </p>
    <p>
      To support training and evaluation, we introduce <strong>XDRive</strong>, a large-scale synthetic 3D HDR benchmark built with CARLA. 
      XDRive provides multimodal ground truth, including HDR frames, aligned multi-exposure LDRs, optical flow, depth maps, and camera poses, captured under diverse lighting and motion conditions. This dataset enables joint optimization for HDR imaging and 3D vision tasks such as monocular depth estimation.
    </p>
    <p>
      Experiments show that <strong>HDRFlow++</strong>, trained with XDRive, achieves up to +2.1 dB improvement in PSNR<sub>T</sub> and consistently better SSIM<sub>T</sub> 
      across local, ego, and global motion scenarios. Additionally, HDR-enhanced inputs improve downstream depth estimation accuracy over standard LDR-based pipelines.
    </p>
    <p>
      Our work bridges HDR reconstruction and 3D perception by introducing a unified training benchmark and a motion-aware fusion model, 
      paving the way for future differentiable visual computing frameworks in dynamic, high-dynamic-range scenes.
    </p>
  </section>

  <!-- Contributions Section -->
  <section id="contributions">
    <h2>Main Contributions</h2>
    <ul>
      <li><strong>HDRFlow++:</strong> Motion-robust HDR reconstruction model with RAFT-enhanced fusion.</li>
      <li><strong>XDRive:</strong> Synthetic 3D HDR dataset containing aligned multi-exposure LDR, GT HDR, depth, and motion ground truth.</li>
      <li><strong>Joint Training Pipeline:</strong> End-to-end differentiable pipeline combining HDR imaging and 3D vision tasks.</li>
      <li><strong>Benchmark Analysis:</strong> Performance evaluation under global, local, and ego motion using PSNR<sub>T</sub> and SSIM<sub>T</sub>.</li>
    </ul>
  </section>

  <!-- Results Section -->
  <section id="results">
    <h2>Qualitative Results</h2>
    <div class="grid">
      <figure>
        <img src="assets/results/global_motion.gif" />
        <figcaption>Scene 1: HDR reconstruction under global motion (HDRFlow++)</figcaption>
      </figure>
      <figure>
        <img src="assets/results/depth_estimation.gif" />
        <figcaption>Scene 2: Monocular depth estimation improves using HDR input</figcaption>
      </figure>
    </div>
  </section>

  <!-- Demo Section -->
  <section id="demo">
    <h2>Interactive Demo</h2>
    <canvas id="viewer"></canvas>
    <p class="note">View reconstructed HDR frame and 3D perception overlay</p>
  </section>

  <!-- BibTeX + Links -->
  <section id="resources">
    <h2>BibTeX</h2>
    <pre>
@misc{lee2025hdrflowpp,
  title={HDRFlow++: Benchmarking HDR Reconstruction under Global Motions},
  author={Lee, Jinwoo and Kim, Janghyun and Kim, Seungjae and Park, Jiheon and Bin, Heejin},
  howpublished={CS470 Project, KAIST},
  year={2025}
}
    </pre>
    <p>
      <a href="https://drive.google.com/file/d/18_Ip8usMrJoTjKBHDozhMRNvL6L2hAhg/view?usp=share_link">[Poster]</a> ·
      <a href="https://github.com/cinescope-wkr/XDRive">[Code]</a> ·
      <a href="https://drive.google.com/drive/folders/1l31fy8DaN4-H1oFoLqq5kpuk5f7iFIq_?usp=share_link">[Dataset]</a> ·
      <a href="https://jak-cal.github.io/XDRive_docs/">[Project Page]</a>
    </p>
  </section>

  <script src="js/main.js"></script>
</body>
</html>
